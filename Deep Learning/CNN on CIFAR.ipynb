{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfADnOe7tfaz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HZ8IRpzEcAJ",
        "colab_type": "code",
        "outputId": "f3915975-6aec-4bb9-a3e7-51d1c9a00577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3L2D7grtnvQ",
        "colab_type": "text"
      },
      "source": [
        "## 2. Loading the dataset(Train and Test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLY3D8htFgWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "  (X_train, y_train), (X_test, y_test)= tf.keras.datasets.cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, num_classes) \n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzo9fifOFzAk",
        "colab_type": "code",
        "outputId": "42633032-c0ae-4799-9a7c-2ec07c8e030d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, y_train,X_test,y_test = load_dataset()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S9tr-02FHn2",
        "colab_type": "code",
        "outputId": "8ba86a99-187d-489b-fc5a-f3c01fbaddba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34G90JYFJxZ",
        "colab_type": "code",
        "outputId": "83a41ab0-2b7e-44e4-d247-fd6e7e4c5131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVb0lgztum-",
        "colab_type": "text"
      },
      "source": [
        "## 3. Standardizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O392emvGcDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "  \n",
        "X_train,X_test=prep_pixels(X_train,X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7ws2R_muJz3",
        "colab_type": "text"
      },
      "source": [
        "## 4. Data Augumentation Example with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82YpscusGxWW",
        "colab_type": "code",
        "outputId": "2a124185-0c46-434e-8a4d-d111bdee4d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "first_image=X_train[1]\n",
        "print(first_image.shape)\n",
        "first_img = expand_dims(first_image, 0)\n",
        "print(first_img.shape)\n",
        "#pyplot.imshow(first_img[0])\n",
        "\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(height_shift_range=0.5)\n",
        "# prepare iterator\n",
        "it = datagen.flow(first_img, batch_size=1)\n",
        "# generate samples and plot\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# generate batch of images\n",
        "\tbatch = it.next()\n",
        "\t# convert to unsigned integers for viewing\n",
        "\timage = (batch[0]*255).astype('uint8')\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n",
            "(1, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaxdHlbsPBSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFGS86CuuP_1",
        "colab_type": "text"
      },
      "source": [
        "## 5. Creating the DenseNet Basic Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ARgtu8uipum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers. MaxPooling2D(pool_size=(2,2))(relu)\n",
        "    \n",
        "    output = layers.Conv2D(filters=10,kernel_size=(2,2),activation='softmax')(AvgPooling)\n",
        "   \n",
        "    flat = layers.Flatten()(output)    \n",
        "    return flat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geCkDfhKiyKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f92e5df0-3c9d-4229-8518-4284a0155e11"
      },
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0\n",
        "l = 12\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(32, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D,num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, 64, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, 64, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, 32, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoNwFiMwivB1",
        "colab_type": "code",
        "outputId": "13ab4d90-d1c7-42f3-c19d-3b89e2794f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(lr = 0.1,momentum = 0.9,nesterov = True)\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.compile(sgd,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 6)    4800        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 38)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 38)   152         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 38)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 6)    5700        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 44)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 44)   176         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 44)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 6)    6600        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 50)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 50)   200         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 50)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 6)    7500        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 56)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 56)   224         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 56)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 6)    8400        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 62)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 62)   248         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 62)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 6)    9300        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 68)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 68)   272         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 68)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 6)    10200       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 74)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 74)   296         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 74)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 6)    11100       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 80)   0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 6)    12000       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 86)   0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 86)   344         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 86)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 6)    12900       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 92)   0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 92)   368         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 92)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 6)    13800       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 98)   0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 98)   392         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 98)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 6)    14700       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 104)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 104)  416         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 104)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 32)   83200       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 32)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 6)    4800        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 38)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 38)   152         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 38)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 6)    5700        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 44)   0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 44)   176         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 44)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 6)    6600        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 50)   0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 50)   200         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 50)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 6)    7500        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 56)   0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 56)   224         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 56)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 6)    8400        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 62)   0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 62)   248         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 62)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 6)    9300        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 68)   0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 68)   272         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 68)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 6)    10200       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 74)   0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 74)   296         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 74)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 6)    11100       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 80)   0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 80)   320         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 80)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 6)    12000       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 86)   0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 86)   344         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 86)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 6)    12900       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 92)   0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 92)   368         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 92)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 6)    13800       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 98)   0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 98)   392         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 98)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 6)    14700       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 104)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 104)  416         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 104)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   83200       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 32)     0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 32)     128         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 32)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 6)      4800        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 38)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 38)     152         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 38)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 6)      5700        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 44)     0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 44)     176         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 44)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 6)      6600        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 50)     0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 50)     200         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 50)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 6)      7500        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 56)     0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 56)     224         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 56)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 6)      8400        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 62)     0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 62)     248         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 62)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 6)      9300        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 68)     0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 68)     272         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 68)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 6)      10200       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 74)     0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 74)     296         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 74)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 6)      11100       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 80)     0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 80)     320         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 80)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 6)      12000       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 86)     0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 86)     344         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 86)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 6)      12900       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 92)     0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 92)     368         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 92)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 6)      13800       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 98)     0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 98)     392         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 98)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 6)      14700       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 104)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 104)    416         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 104)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 16)     41600       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 16)     0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 16)     64          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 16)     0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 6)      2400        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 22)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 22)     88          concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 22)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 6)      3300        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 28)     0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 28)     112         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 28)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 6)      4200        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 34)     0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 34)     136         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 34)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 6)      5100        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 40)     0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 40)     160         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 40)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 6)      6000        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 46)     0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 46)     184         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 46)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 6)      6900        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 52)     0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 52)     208         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 52)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 6)      7800        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 58)     0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 58)     232         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 58)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 6)      8700        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 64)     0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 64)     256         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 64)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 6)      9600        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 70)     0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 70)     280         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 70)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 6)      10500       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 76)     0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 76)     304         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 76)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 6)      11400       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 82)     0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 82)     328         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 82)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 6)      12300       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 88)     0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 88)     352         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 88)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 2, 2, 88)     0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 1, 1, 10)     3530        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           conv2d_52[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 664,906\n",
            "Trainable params: 658,250\n",
            "Non-trainable params: 6,656\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOOyROXuYb_",
        "colab_type": "text"
      },
      "source": [
        "## 6. Running the model with data augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGlJ8wVZjgw6",
        "colab_type": "code",
        "outputId": "2ec3b92f-07b5-467e-d5b9-1d8c2889d192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "datagen = ImageDataGenerator( zoom_range=0.3,width_shift_range=0.1,rotation_range=15,height_shift_range=0.1, horizontal_flip=True)\n",
        "# prepare iterator\n",
        "it_train = datagen.flow(X_train, y_train, batch_size=128)\n",
        "# fit model\n",
        "steps = int(X_train.shape[0] / 128)\n",
        "history = model.fit_generator(it_train, steps_per_epoch=steps, epochs=150, validation_data=(X_test, y_test), verbose=1)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n",
        "# learning curves\n",
        "summarize_diagnostics(history)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "389/390 [============================>.] - ETA: 0s - loss: 2.3142 - acc: 0.2115Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 8s 803us/sample - loss: 2.6010 - acc: 0.1708\n",
            "390/390 [==============================] - 136s 349ms/step - loss: 2.3141 - acc: 0.2117 - val_loss: 2.6096 - val_acc: 0.1708\n",
            "Epoch 2/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.9132 - acc: 0.3177Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.7343 - acc: 0.3758\n",
            "390/390 [==============================] - 122s 313ms/step - loss: 1.9130 - acc: 0.3178 - val_loss: 1.7375 - val_acc: 0.3758\n",
            "Epoch 3/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.7051 - acc: 0.3763Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 681us/sample - loss: 1.4429 - acc: 0.4104\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 1.7047 - acc: 0.3766 - val_loss: 1.6098 - val_acc: 0.4104\n",
            "Epoch 4/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.5894 - acc: 0.4215Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 1.5287 - acc: 0.4313\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 1.5894 - acc: 0.4215 - val_loss: 1.6173 - val_acc: 0.4313\n",
            "Epoch 5/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.4996 - acc: 0.4568Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.4395 - acc: 0.4562\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.4993 - acc: 0.4568 - val_loss: 1.5374 - val_acc: 0.4562\n",
            "Epoch 6/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.4130 - acc: 0.4903Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.2582 - acc: 0.4986\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.4132 - acc: 0.4902 - val_loss: 1.3912 - val_acc: 0.4986\n",
            "Epoch 7/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.3398 - acc: 0.5156Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.3046 - acc: 0.5052\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.3398 - acc: 0.5156 - val_loss: 1.4255 - val_acc: 0.5052\n",
            "Epoch 8/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.2637 - acc: 0.5477Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 1.1996 - acc: 0.5865\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.2639 - acc: 0.5476 - val_loss: 1.1405 - val_acc: 0.5865\n",
            "Epoch 9/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.2040 - acc: 0.5709Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.2560 - acc: 0.5832\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.2039 - acc: 0.5709 - val_loss: 1.1841 - val_acc: 0.5832\n",
            "Epoch 10/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.1491 - acc: 0.5914Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 1.0802 - acc: 0.6372\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.1492 - acc: 0.5914 - val_loss: 1.0270 - val_acc: 0.6372\n",
            "Epoch 11/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.0916 - acc: 0.6127Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.1504 - acc: 0.6024\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 1.0917 - acc: 0.6126 - val_loss: 1.1253 - val_acc: 0.6024\n",
            "Epoch 12/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.0415 - acc: 0.6309Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 681us/sample - loss: 1.0354 - acc: 0.6362\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 1.0412 - acc: 0.6310 - val_loss: 1.0282 - val_acc: 0.6362\n",
            "Epoch 13/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.9992 - acc: 0.6486Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.0923 - acc: 0.6260\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.9991 - acc: 0.6487 - val_loss: 1.0923 - val_acc: 0.6260\n",
            "Epoch 14/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.9594 - acc: 0.6605Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 1.0744 - acc: 0.6619\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.9589 - acc: 0.6608 - val_loss: 0.9685 - val_acc: 0.6619\n",
            "Epoch 15/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.9242 - acc: 0.6737Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 1.0580 - acc: 0.6424\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.9243 - acc: 0.6736 - val_loss: 1.1069 - val_acc: 0.6424\n",
            "Epoch 16/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.6891Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 1.1856 - acc: 0.6391\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.8874 - acc: 0.6892 - val_loss: 1.1039 - val_acc: 0.6391\n",
            "Epoch 17/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.8643 - acc: 0.6954Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.8146 - acc: 0.6823\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.8641 - acc: 0.6954 - val_loss: 0.8757 - val_acc: 0.6823\n",
            "Epoch 18/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.8247 - acc: 0.7099Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 1.1573 - acc: 0.6424\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.8245 - acc: 0.7100 - val_loss: 1.1125 - val_acc: 0.6424\n",
            "Epoch 19/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.8015 - acc: 0.7206Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.8249 - acc: 0.7108\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.8015 - acc: 0.7206 - val_loss: 0.8551 - val_acc: 0.7108\n",
            "Epoch 20/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7284Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7226 - acc: 0.7064\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.7691 - acc: 0.7284 - val_loss: 0.8693 - val_acc: 0.7064\n",
            "Epoch 21/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.7491 - acc: 0.7363Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.8316 - acc: 0.7302\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.7491 - acc: 0.7363 - val_loss: 0.7963 - val_acc: 0.7302\n",
            "Epoch 22/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.7216 - acc: 0.7487Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7701 - acc: 0.7271\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.7221 - acc: 0.7484 - val_loss: 0.7905 - val_acc: 0.7271\n",
            "Epoch 23/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6993 - acc: 0.7544Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7669 - acc: 0.7505\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.6993 - acc: 0.7544 - val_loss: 0.7238 - val_acc: 0.7505\n",
            "Epoch 24/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6893 - acc: 0.7582Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.8762 - acc: 0.7438\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.6895 - acc: 0.7582 - val_loss: 0.7562 - val_acc: 0.7438\n",
            "Epoch 25/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6670 - acc: 0.7653Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7641 - acc: 0.7435\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.6670 - acc: 0.7654 - val_loss: 0.7584 - val_acc: 0.7435\n",
            "Epoch 26/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.7727Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.6954 - acc: 0.7635\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.6469 - acc: 0.7727 - val_loss: 0.7152 - val_acc: 0.7635\n",
            "Epoch 27/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6280 - acc: 0.7809Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.7138 - acc: 0.7125\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.6284 - acc: 0.7808 - val_loss: 0.8352 - val_acc: 0.7125\n",
            "Epoch 28/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.7848Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.6747 - acc: 0.7576\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.6203 - acc: 0.7849 - val_loss: 0.7295 - val_acc: 0.7576\n",
            "Epoch 29/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.7905Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5433 - acc: 0.7626\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.6005 - acc: 0.7907 - val_loss: 0.7132 - val_acc: 0.7626\n",
            "Epoch 30/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.7934Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.6034 - acc: 0.7949\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5905 - acc: 0.7933 - val_loss: 0.6083 - val_acc: 0.7949\n",
            "Epoch 31/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5714 - acc: 0.8025Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.5829 - acc: 0.8095\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5713 - acc: 0.8025 - val_loss: 0.5701 - val_acc: 0.8095\n",
            "Epoch 32/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.8033Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.8379 - acc: 0.7678\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5661 - acc: 0.8033 - val_loss: 0.7080 - val_acc: 0.7678\n",
            "Epoch 33/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.8095Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5703 - acc: 0.8107\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5518 - acc: 0.8095 - val_loss: 0.5615 - val_acc: 0.8107\n",
            "Epoch 34/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.8138Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.5898 - acc: 0.7778\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.5406 - acc: 0.8137 - val_loss: 0.6652 - val_acc: 0.7778\n",
            "Epoch 35/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5366 - acc: 0.8117Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.6757 - acc: 0.8171\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5364 - acc: 0.8118 - val_loss: 0.5685 - val_acc: 0.8171\n",
            "Epoch 36/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.8156Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.7191 - acc: 0.8110\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.5255 - acc: 0.8157 - val_loss: 0.5874 - val_acc: 0.8110\n",
            "Epoch 37/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.8215Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.7271 - acc: 0.8093\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.5127 - acc: 0.8215 - val_loss: 0.5859 - val_acc: 0.8093\n",
            "Epoch 38/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.8222Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.6056 - acc: 0.8069\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.5099 - acc: 0.8221 - val_loss: 0.6073 - val_acc: 0.8069\n",
            "Epoch 39/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.8275Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6909 - acc: 0.7778\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.5002 - acc: 0.8275 - val_loss: 0.6976 - val_acc: 0.7778\n",
            "Epoch 40/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4842 - acc: 0.8322Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6202 - acc: 0.8041\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4839 - acc: 0.8323 - val_loss: 0.6049 - val_acc: 0.8041\n",
            "Epoch 41/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4829 - acc: 0.8320Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7460 - acc: 0.8255\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4827 - acc: 0.8320 - val_loss: 0.5320 - val_acc: 0.8255\n",
            "Epoch 42/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8373Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.5561 - acc: 0.8119\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4753 - acc: 0.8373 - val_loss: 0.5864 - val_acc: 0.8119\n",
            "Epoch 43/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8362Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5759 - acc: 0.8174\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4724 - acc: 0.8361 - val_loss: 0.6009 - val_acc: 0.8174\n",
            "Epoch 44/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4607 - acc: 0.8420Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5608 - acc: 0.8205\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4605 - acc: 0.8419 - val_loss: 0.5628 - val_acc: 0.8205\n",
            "Epoch 45/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8386Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.7237 - acc: 0.8047\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4593 - acc: 0.8386 - val_loss: 0.6367 - val_acc: 0.8047\n",
            "Epoch 46/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8459Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.8686 - acc: 0.7656\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.4483 - acc: 0.8458 - val_loss: 0.7581 - val_acc: 0.7656\n",
            "Epoch 47/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.8439Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.6631 - acc: 0.7844\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4476 - acc: 0.8439 - val_loss: 0.6910 - val_acc: 0.7844\n",
            "Epoch 48/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8485Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5492 - acc: 0.8305\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4357 - acc: 0.8485 - val_loss: 0.5267 - val_acc: 0.8305\n",
            "Epoch 49/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8502Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.4892 - acc: 0.8322\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4345 - acc: 0.8502 - val_loss: 0.5108 - val_acc: 0.8322\n",
            "Epoch 50/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8543Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7183 - acc: 0.8172\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4201 - acc: 0.8541 - val_loss: 0.5612 - val_acc: 0.8172\n",
            "Epoch 51/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4223 - acc: 0.8524Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.7260 - acc: 0.8331\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.4228 - acc: 0.8522 - val_loss: 0.5381 - val_acc: 0.8331\n",
            "Epoch 52/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4175 - acc: 0.8551Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7029 - acc: 0.8216\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.4175 - acc: 0.8551 - val_loss: 0.5579 - val_acc: 0.8216\n",
            "Epoch 53/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4102 - acc: 0.8576Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5685 - acc: 0.8232\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.4101 - acc: 0.8576 - val_loss: 0.5641 - val_acc: 0.8232\n",
            "Epoch 54/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8568Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 688us/sample - loss: 0.6529 - acc: 0.8173\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4116 - acc: 0.8568 - val_loss: 0.5880 - val_acc: 0.8173\n",
            "Epoch 55/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3999 - acc: 0.8608Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5615 - acc: 0.8272\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.4000 - acc: 0.8607 - val_loss: 0.5529 - val_acc: 0.8272\n",
            "Epoch 56/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8628Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.6676 - acc: 0.8252\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.3970 - acc: 0.8629 - val_loss: 0.5724 - val_acc: 0.8252\n",
            "Epoch 57/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3930 - acc: 0.8627Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.6445 - acc: 0.8228\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.3930 - acc: 0.8628 - val_loss: 0.5491 - val_acc: 0.8228\n",
            "Epoch 58/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8642Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.5132 - acc: 0.8381\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3890 - acc: 0.8641 - val_loss: 0.5252 - val_acc: 0.8381\n",
            "Epoch 59/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8670Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4494 - acc: 0.8404\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3834 - acc: 0.8672 - val_loss: 0.5169 - val_acc: 0.8404\n",
            "Epoch 60/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8673Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5208 - acc: 0.8239\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3820 - acc: 0.8672 - val_loss: 0.5758 - val_acc: 0.8239\n",
            "Epoch 61/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3772 - acc: 0.8697Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3934 - acc: 0.8379\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3770 - acc: 0.8698 - val_loss: 0.5113 - val_acc: 0.8379\n",
            "Epoch 62/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3702 - acc: 0.8703Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5040 - acc: 0.8390\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3703 - acc: 0.8703 - val_loss: 0.5074 - val_acc: 0.8390\n",
            "Epoch 63/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8715Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.6510 - acc: 0.8203\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3682 - acc: 0.8716 - val_loss: 0.5990 - val_acc: 0.8203\n",
            "Epoch 64/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8726Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.5929 - acc: 0.8252\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3691 - acc: 0.8726 - val_loss: 0.5481 - val_acc: 0.8252\n",
            "Epoch 65/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8740Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.6075 - acc: 0.8367\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3630 - acc: 0.8739 - val_loss: 0.5309 - val_acc: 0.8367\n",
            "Epoch 66/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8768Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5466 - acc: 0.8445\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3591 - acc: 0.8769 - val_loss: 0.4958 - val_acc: 0.8445\n",
            "Epoch 67/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3577 - acc: 0.8765Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.4115 - acc: 0.8572\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.3579 - acc: 0.8765 - val_loss: 0.4357 - val_acc: 0.8572\n",
            "Epoch 68/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8782Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3873 - acc: 0.8438\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3500 - acc: 0.8781 - val_loss: 0.4866 - val_acc: 0.8438\n",
            "Epoch 69/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.8782Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.6224 - acc: 0.8480\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.3494 - acc: 0.8782 - val_loss: 0.5050 - val_acc: 0.8480\n",
            "Epoch 70/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3468 - acc: 0.8798Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.5561 - acc: 0.8504\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3469 - acc: 0.8798 - val_loss: 0.4609 - val_acc: 0.8504\n",
            "Epoch 71/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.8806Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.3251 - acc: 0.8644\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3440 - acc: 0.8807 - val_loss: 0.4257 - val_acc: 0.8644\n",
            "Epoch 72/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.8827Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4916 - acc: 0.8475\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3413 - acc: 0.8827 - val_loss: 0.4964 - val_acc: 0.8475\n",
            "Epoch 73/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8819Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4607 - acc: 0.8454\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3406 - acc: 0.8819 - val_loss: 0.4928 - val_acc: 0.8454\n",
            "Epoch 74/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8834Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3535 - acc: 0.8475\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3337 - acc: 0.8834 - val_loss: 0.4864 - val_acc: 0.8475\n",
            "Epoch 75/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8834Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.4509 - acc: 0.8588\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3336 - acc: 0.8835 - val_loss: 0.4590 - val_acc: 0.8588\n",
            "Epoch 76/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3316 - acc: 0.8858Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3845 - acc: 0.8605\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3315 - acc: 0.8858 - val_loss: 0.4468 - val_acc: 0.8605\n",
            "Epoch 77/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.8849Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6471 - acc: 0.8358\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3296 - acc: 0.8847 - val_loss: 0.5611 - val_acc: 0.8358\n",
            "Epoch 78/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.8892Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6364 - acc: 0.8279\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3201 - acc: 0.8891 - val_loss: 0.5898 - val_acc: 0.8279\n",
            "Epoch 79/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8854Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.4869 - acc: 0.8551\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3264 - acc: 0.8854 - val_loss: 0.4609 - val_acc: 0.8551\n",
            "Epoch 80/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8885Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5914 - acc: 0.8390\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3179 - acc: 0.8885 - val_loss: 0.5209 - val_acc: 0.8390\n",
            "Epoch 81/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.8888Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6056 - acc: 0.8303\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3172 - acc: 0.8888 - val_loss: 0.6108 - val_acc: 0.8303\n",
            "Epoch 82/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.8884Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4094 - acc: 0.8595\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3194 - acc: 0.8884 - val_loss: 0.4432 - val_acc: 0.8595\n",
            "Epoch 83/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8904Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.4198 - acc: 0.8412\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3139 - acc: 0.8905 - val_loss: 0.4938 - val_acc: 0.8412\n",
            "Epoch 84/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3098 - acc: 0.8931Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.6156 - acc: 0.8486\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3097 - acc: 0.8931 - val_loss: 0.4925 - val_acc: 0.8486\n",
            "Epoch 85/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.8925Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.5134 - acc: 0.8608\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3086 - acc: 0.8925 - val_loss: 0.4436 - val_acc: 0.8608\n",
            "Epoch 86/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.8938Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.4166 - acc: 0.8627\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3071 - acc: 0.8940 - val_loss: 0.4455 - val_acc: 0.8627\n",
            "Epoch 87/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8927Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.5794 - acc: 0.8433\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.3032 - acc: 0.8927 - val_loss: 0.5212 - val_acc: 0.8433\n",
            "Epoch 88/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8934Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 681us/sample - loss: 0.4682 - acc: 0.8574\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3079 - acc: 0.8934 - val_loss: 0.4639 - val_acc: 0.8574\n",
            "Epoch 89/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3004 - acc: 0.8951Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4168 - acc: 0.8705\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.3005 - acc: 0.8951 - val_loss: 0.3984 - val_acc: 0.8705\n",
            "Epoch 90/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.8971Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3338 - acc: 0.8628\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2966 - acc: 0.8971 - val_loss: 0.4527 - val_acc: 0.8628\n",
            "Epoch 91/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.8984Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 741us/sample - loss: 0.4837 - acc: 0.8567\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2931 - acc: 0.8985 - val_loss: 0.4549 - val_acc: 0.8567\n",
            "Epoch 92/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2959 - acc: 0.8962Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 688us/sample - loss: 0.5019 - acc: 0.8475\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2956 - acc: 0.8963 - val_loss: 0.5124 - val_acc: 0.8475\n",
            "Epoch 93/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8986Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4859 - acc: 0.8565\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2910 - acc: 0.8986 - val_loss: 0.4774 - val_acc: 0.8565\n",
            "Epoch 94/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8959Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4481 - acc: 0.8539\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2983 - acc: 0.8959 - val_loss: 0.4714 - val_acc: 0.8539\n",
            "Epoch 95/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.8980Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.5789 - acc: 0.8361\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2937 - acc: 0.8981 - val_loss: 0.5756 - val_acc: 0.8361\n",
            "Epoch 96/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.8993Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3732 - acc: 0.8748\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2884 - acc: 0.8992 - val_loss: 0.3957 - val_acc: 0.8748\n",
            "Epoch 97/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.9000Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.2984 - acc: 0.8659\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2857 - acc: 0.9000 - val_loss: 0.4214 - val_acc: 0.8659\n",
            "Epoch 98/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9016Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3855 - acc: 0.8779\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2813 - acc: 0.9016 - val_loss: 0.3824 - val_acc: 0.8779\n",
            "Epoch 99/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9006Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3590 - acc: 0.8648\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2834 - acc: 0.9006 - val_loss: 0.4384 - val_acc: 0.8648\n",
            "Epoch 100/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2808 - acc: 0.9014Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4021 - acc: 0.8645\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2810 - acc: 0.9012 - val_loss: 0.4343 - val_acc: 0.8645\n",
            "Epoch 101/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2796 - acc: 0.9015Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3831 - acc: 0.8775\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2796 - acc: 0.9014 - val_loss: 0.4005 - val_acc: 0.8775\n",
            "Epoch 102/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9037Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5363 - acc: 0.8551\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2780 - acc: 0.9038 - val_loss: 0.4663 - val_acc: 0.8551\n",
            "Epoch 103/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.9041Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.4848 - acc: 0.8333\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2718 - acc: 0.9041 - val_loss: 0.6273 - val_acc: 0.8333\n",
            "Epoch 104/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.9048Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3395 - acc: 0.8637\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2748 - acc: 0.9047 - val_loss: 0.4364 - val_acc: 0.8637\n",
            "Epoch 105/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9063Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3611 - acc: 0.8676\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2691 - acc: 0.9063 - val_loss: 0.4264 - val_acc: 0.8676\n",
            "Epoch 106/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9064Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.3896 - acc: 0.8626\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2689 - acc: 0.9061 - val_loss: 0.4614 - val_acc: 0.8626\n",
            "Epoch 107/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9061Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 682us/sample - loss: 0.4045 - acc: 0.8630\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2693 - acc: 0.9062 - val_loss: 0.4549 - val_acc: 0.8630\n",
            "Epoch 108/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9066Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4534 - acc: 0.8705\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2680 - acc: 0.9066 - val_loss: 0.4362 - val_acc: 0.8705\n",
            "Epoch 109/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9063Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3617 - acc: 0.8758\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2678 - acc: 0.9063 - val_loss: 0.3894 - val_acc: 0.8758\n",
            "Epoch 110/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9107Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3244 - acc: 0.8728\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2560 - acc: 0.9107 - val_loss: 0.4436 - val_acc: 0.8728\n",
            "Epoch 111/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9117Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.5634 - acc: 0.8774\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2573 - acc: 0.9116 - val_loss: 0.4087 - val_acc: 0.8774\n",
            "Epoch 112/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.9090Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4344 - acc: 0.8541\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2627 - acc: 0.9090 - val_loss: 0.5172 - val_acc: 0.8541\n",
            "Epoch 113/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2612 - acc: 0.9092Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3890 - acc: 0.8656\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2613 - acc: 0.9091 - val_loss: 0.4676 - val_acc: 0.8656\n",
            "Epoch 114/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2585 - acc: 0.9096Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 687us/sample - loss: 0.4019 - acc: 0.8391\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2585 - acc: 0.9096 - val_loss: 0.5282 - val_acc: 0.8391\n",
            "Epoch 115/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9108Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3110 - acc: 0.8726\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2541 - acc: 0.9109 - val_loss: 0.4200 - val_acc: 0.8726\n",
            "Epoch 116/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9105Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.3618 - acc: 0.8666\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2558 - acc: 0.9103 - val_loss: 0.4377 - val_acc: 0.8666\n",
            "Epoch 117/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9113Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 677us/sample - loss: 0.4844 - acc: 0.8668\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2526 - acc: 0.9113 - val_loss: 0.4628 - val_acc: 0.8668\n",
            "Epoch 118/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.9122Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3898 - acc: 0.8698\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2514 - acc: 0.9122 - val_loss: 0.4213 - val_acc: 0.8698\n",
            "Epoch 119/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2522 - acc: 0.9125Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 675us/sample - loss: 0.3810 - acc: 0.8634\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2521 - acc: 0.9124 - val_loss: 0.4877 - val_acc: 0.8634\n",
            "Epoch 120/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9132Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 674us/sample - loss: 0.5092 - acc: 0.8697\n",
            "390/390 [==============================] - 122s 312ms/step - loss: 0.2500 - acc: 0.9133 - val_loss: 0.4417 - val_acc: 0.8697\n",
            "Epoch 121/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9146Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 675us/sample - loss: 0.4284 - acc: 0.8592\n",
            "390/390 [==============================] - 122s 312ms/step - loss: 0.2467 - acc: 0.9145 - val_loss: 0.4831 - val_acc: 0.8592\n",
            "Epoch 122/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9134Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 687us/sample - loss: 0.4087 - acc: 0.8743\n",
            "390/390 [==============================] - 122s 313ms/step - loss: 0.2467 - acc: 0.9134 - val_loss: 0.4112 - val_acc: 0.8743\n",
            "Epoch 123/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2453 - acc: 0.9150Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.3965 - acc: 0.8791\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2453 - acc: 0.9150 - val_loss: 0.4078 - val_acc: 0.8791\n",
            "Epoch 124/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9152Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.4710 - acc: 0.8543\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2430 - acc: 0.9153 - val_loss: 0.4988 - val_acc: 0.8543\n",
            "Epoch 125/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9171Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4325 - acc: 0.8807\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2407 - acc: 0.9171 - val_loss: 0.3991 - val_acc: 0.8807\n",
            "Epoch 126/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9142Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3396 - acc: 0.8599\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2459 - acc: 0.9142 - val_loss: 0.4723 - val_acc: 0.8599\n",
            "Epoch 127/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9168Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4483 - acc: 0.8745\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2400 - acc: 0.9168 - val_loss: 0.4242 - val_acc: 0.8745\n",
            "Epoch 128/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9177Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.5178 - acc: 0.8600\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2348 - acc: 0.9177 - val_loss: 0.5088 - val_acc: 0.8600\n",
            "Epoch 129/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9190Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.4506 - acc: 0.8715\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2355 - acc: 0.9189 - val_loss: 0.4447 - val_acc: 0.8715\n",
            "Epoch 130/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.9184Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 687us/sample - loss: 0.3483 - acc: 0.8783\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2374 - acc: 0.9184 - val_loss: 0.4048 - val_acc: 0.8783\n",
            "Epoch 131/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9187Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4152 - acc: 0.8704\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2296 - acc: 0.9187 - val_loss: 0.4302 - val_acc: 0.8704\n",
            "Epoch 132/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9183Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4733 - acc: 0.8503\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2346 - acc: 0.9183 - val_loss: 0.5437 - val_acc: 0.8503\n",
            "Epoch 133/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9184Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3311 - acc: 0.8715\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2357 - acc: 0.9184 - val_loss: 0.4327 - val_acc: 0.8715\n",
            "Epoch 134/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9200Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4976 - acc: 0.8584\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2306 - acc: 0.9200 - val_loss: 0.5215 - val_acc: 0.8584\n",
            "Epoch 135/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9174Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.2104 - acc: 0.8937\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2359 - acc: 0.9173 - val_loss: 0.3486 - val_acc: 0.8937\n",
            "Epoch 136/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9205Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3443 - acc: 0.8774\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2281 - acc: 0.9205 - val_loss: 0.4236 - val_acc: 0.8774\n",
            "Epoch 137/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9231Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4165 - acc: 0.8614\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2216 - acc: 0.9231 - val_loss: 0.4823 - val_acc: 0.8614\n",
            "Epoch 138/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9172Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.4498 - acc: 0.8784\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2365 - acc: 0.9172 - val_loss: 0.4178 - val_acc: 0.8784\n",
            "Epoch 139/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9220Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3852 - acc: 0.8890\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2230 - acc: 0.9221 - val_loss: 0.3699 - val_acc: 0.8890\n",
            "Epoch 140/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.9193Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4523 - acc: 0.8713\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2305 - acc: 0.9194 - val_loss: 0.4321 - val_acc: 0.8713\n",
            "Epoch 141/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9206Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.7487 - acc: 0.8683\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2271 - acc: 0.9207 - val_loss: 0.4827 - val_acc: 0.8683\n",
            "Epoch 142/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9228Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3718 - acc: 0.8685\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2226 - acc: 0.9228 - val_loss: 0.4676 - val_acc: 0.8685\n",
            "Epoch 143/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9225Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4203 - acc: 0.8798\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2222 - acc: 0.9225 - val_loss: 0.4082 - val_acc: 0.8798\n",
            "Epoch 144/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9205Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.2884 - acc: 0.8733\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2269 - acc: 0.9205 - val_loss: 0.4086 - val_acc: 0.8733\n",
            "Epoch 145/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9217Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 686us/sample - loss: 0.4271 - acc: 0.8766\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2247 - acc: 0.9217 - val_loss: 0.4442 - val_acc: 0.8766\n",
            "Epoch 146/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9221Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3679 - acc: 0.8873\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2200 - acc: 0.9221 - val_loss: 0.3766 - val_acc: 0.8873\n",
            "Epoch 147/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9230Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 685us/sample - loss: 0.3666 - acc: 0.8618\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2172 - acc: 0.9231 - val_loss: 0.4782 - val_acc: 0.8618\n",
            "Epoch 148/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9234Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.4288 - acc: 0.8834\n",
            "390/390 [==============================] - 123s 315ms/step - loss: 0.2196 - acc: 0.9234 - val_loss: 0.3804 - val_acc: 0.8834\n",
            "Epoch 149/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9244Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 683us/sample - loss: 0.4994 - acc: 0.8776\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.2159 - acc: 0.9243 - val_loss: 0.4247 - val_acc: 0.8776\n",
            "Epoch 150/150\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9254Epoch 1/150\n",
            "10000/390 [=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 7s 684us/sample - loss: 0.3688 - acc: 0.8840\n",
            "390/390 [==============================] - 123s 314ms/step - loss: 0.2162 - acc: 0.9253 - val_loss: 0.3828 - val_acc: 0.8840\n",
            "> 88.400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAACSCAYAAABsboAjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG4Zh+BwTasMwDJ9jQm0YhuFz/h8ydd0KSAKMMAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXpinmsFum1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3addfced-fddd-4c6c-f8d1-e0e0d8756799"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "conclusion= PrettyTable()\n",
        "conclusion.field_names = [ \"Model\", 'epochs','Train Loss','Test Loss',\"Train Accuracy\",'Test Accuracy']\n",
        "conclusion.add_row([\"CNN DenseNet\",150, 0.2162, 0.3828,0.9253,0.8840])\n",
        "\n",
        "\n",
        "print(conclusion)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------+------------+-----------+----------------+---------------+\n",
            "|    Model     | epochs | Train Loss | Test Loss | Train Accuracy | Test Accuracy |\n",
            "+--------------+--------+------------+-----------+----------------+---------------+\n",
            "| CNN DenseNet |  150   |   0.2162   |   0.3828  |     0.9253     |     0.884     |\n",
            "+--------------+--------+------------+-----------+----------------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}